{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "vbe_iLL__bIw"
      },
      "outputs": [],
      "source": [
        "\n",
        "is_auto_eda = False # run sweetviz report\n",
        "is_small_spacy = True\n",
        "is_sample_df = True\n",
        "sample_fraction = 0.1 # fraction of sampling from train and test DataFrames\n",
        "num_epochs = 2"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "1D-bAE4q_gZE"
      },
      "outputs": [],
      "source": [
        "\n",
        "# needed for BERT model\n",
        "!pip install -qq transformers==4.28.0  # (-qq is for quite)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Collecting wordcloud\n",
            "  Downloading wordcloud-1.9.3-cp310-cp310-macosx_11_0_arm64.whl.metadata (3.4 kB)\n",
            "Requirement already satisfied: numpy>=1.6.1 in /Users/chandramaniyadav/miniconda3/lib/python3.10/site-packages (from wordcloud) (1.23.5)\n",
            "Requirement already satisfied: pillow in /Users/chandramaniyadav/miniconda3/lib/python3.10/site-packages (from wordcloud) (9.4.0)\n",
            "Requirement already satisfied: matplotlib in /Users/chandramaniyadav/miniconda3/lib/python3.10/site-packages (from wordcloud) (3.6.3)\n",
            "Requirement already satisfied: contourpy>=1.0.1 in /Users/chandramaniyadav/miniconda3/lib/python3.10/site-packages (from matplotlib->wordcloud) (1.0.7)\n",
            "Requirement already satisfied: cycler>=0.10 in /Users/chandramaniyadav/miniconda3/lib/python3.10/site-packages (from matplotlib->wordcloud) (0.11.0)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /Users/chandramaniyadav/miniconda3/lib/python3.10/site-packages (from matplotlib->wordcloud) (4.38.0)\n",
            "Requirement already satisfied: kiwisolver>=1.0.1 in /Users/chandramaniyadav/miniconda3/lib/python3.10/site-packages (from matplotlib->wordcloud) (1.4.4)\n",
            "Requirement already satisfied: packaging>=20.0 in /Users/chandramaniyadav/miniconda3/lib/python3.10/site-packages (from matplotlib->wordcloud) (23.0)\n",
            "Requirement already satisfied: pyparsing>=2.2.1 in /Users/chandramaniyadav/miniconda3/lib/python3.10/site-packages (from matplotlib->wordcloud) (3.0.9)\n",
            "Requirement already satisfied: python-dateutil>=2.7 in /Users/chandramaniyadav/miniconda3/lib/python3.10/site-packages (from matplotlib->wordcloud) (2.8.2)\n",
            "Requirement already satisfied: six>=1.5 in /Users/chandramaniyadav/miniconda3/lib/python3.10/site-packages (from python-dateutil>=2.7->matplotlib->wordcloud) (1.16.0)\n",
            "Downloading wordcloud-1.9.3-cp310-cp310-macosx_11_0_arm64.whl (168 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m168.4/168.4 kB\u001b[0m \u001b[31m3.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: wordcloud\n",
            "Successfully installed wordcloud-1.9.3\n",
            "\n",
            "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m23.3.1\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m23.3.2\u001b[0m\n",
            "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpip install --upgrade pip\u001b[0m\n"
          ]
        }
      ],
      "source": [
        "!pip install wordcloud"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "m95AtqET_j2Y"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/Users/chandramaniyadav/miniconda3/lib/python3.10/site-packages/tqdm/auto.py:22: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
            "  from .autonotebook import tqdm as notebook_tqdm\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Using PyTorch version 2.0.1\n"
          ]
        }
      ],
      "source": [
        "import os\n",
        "import random\n",
        "\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "\n",
        "import plotly.express as px\n",
        "import plotly.figure_factory as ff\n",
        "import plotly.graph_objects as go\n",
        "\n",
        "import spacy\n",
        "import spacy.cli\n",
        "from spacy.lang.en.stop_words import STOP_WORDS\n",
        "\n",
        "# for spaCy Text Categorizer\n",
        "from spacy.util import minibatch, compounding\n",
        "from spacy.training.example import Example\n",
        "\n",
        "from wordcloud import WordCloud # See : https://www.kaggle.com/aashita/word-clouds-of-various-shapes\n",
        "\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.svm import LinearSVC\n",
        "from sklearn.naive_bayes import MultinomialNB\n",
        "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n",
        "from sklearn.metrics import classification_report, confusion_matrix\n",
        "\n",
        "from transformers import BertTokenizer, BertForSequenceClassification\n",
        "\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "from torch.optim import AdamW\n",
        "import torch.nn.functional as F # for softmax in Eval\n",
        "\n",
        "from datetime import datetime\n",
        "import pytz # timezone\n",
        "\n",
        "from tqdm import trange # used to make our loops show a smart progress meter\n",
        "\n",
        "# from autocorrect import spell # (TODO: do we really need this?)\n",
        "\n",
        "#torch.manual_seed(0)\n",
        "\n",
        "print(\"Using PyTorch version\", torch.__version__)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "scxHq82f_p7N"
      },
      "outputs": [],
      "source": [
        "\n",
        "pd.set_option(\"display.max_rows\", 100)\n",
        "pd.set_option(\"display.max_columns\",100)\n",
        "pd.set_option(\"display.max_colwidth\", 500)\n",
        "color = sns.color_palette()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "PjiCkLpQ_wTa"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "No GPU available, using the CPU instead.\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "device(type='cpu')"
            ]
          },
          "execution_count": 7,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "\n",
        "# If there's a GPU available...\n",
        "if torch.cuda.is_available():\n",
        "\n",
        "    # Tell PyTorch to use the GPU.\n",
        "    device = torch.device(\"cuda\")\n",
        "\n",
        "    print('There are %d GPU(s) available.' % torch.cuda.device_count())\n",
        "\n",
        "    print('We will use the GPU:', torch.cuda.get_device_name(0))\n",
        "\n",
        "# If not...\n",
        "else:\n",
        "    print('No GPU available, using the CPU instead.')\n",
        "    device = torch.device(\"cpu\") # (TODO: change \"cpu\" to \"device error\"?)\n",
        "device"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "4uRHu5lJ_yGi"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Collecting en-core-web-sm==3.5.0\n",
            "  Downloading https://github.com/explosion/spacy-models/releases/download/en_core_web_sm-3.5.0/en_core_web_sm-3.5.0-py3-none-any.whl (12.8 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m12.8/12.8 MB\u001b[0m \u001b[31m6.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: spacy<3.6.0,>=3.5.0 in /Users/chandramaniyadav/miniconda3/lib/python3.10/site-packages (from en-core-web-sm==3.5.0) (3.5.0)\n",
            "Requirement already satisfied: spacy-legacy<3.1.0,>=3.0.11 in /Users/chandramaniyadav/miniconda3/lib/python3.10/site-packages (from spacy<3.6.0,>=3.5.0->en-core-web-sm==3.5.0) (3.0.12)\n",
            "Requirement already satisfied: spacy-loggers<2.0.0,>=1.0.0 in /Users/chandramaniyadav/miniconda3/lib/python3.10/site-packages (from spacy<3.6.0,>=3.5.0->en-core-web-sm==3.5.0) (1.0.4)\n",
            "Requirement already satisfied: murmurhash<1.1.0,>=0.28.0 in /Users/chandramaniyadav/miniconda3/lib/python3.10/site-packages (from spacy<3.6.0,>=3.5.0->en-core-web-sm==3.5.0) (1.0.9)\n",
            "Requirement already satisfied: cymem<2.1.0,>=2.0.2 in /Users/chandramaniyadav/miniconda3/lib/python3.10/site-packages (from spacy<3.6.0,>=3.5.0->en-core-web-sm==3.5.0) (2.0.7)\n",
            "Requirement already satisfied: preshed<3.1.0,>=3.0.2 in /Users/chandramaniyadav/miniconda3/lib/python3.10/site-packages (from spacy<3.6.0,>=3.5.0->en-core-web-sm==3.5.0) (3.0.8)\n",
            "Requirement already satisfied: thinc<8.2.0,>=8.1.0 in /Users/chandramaniyadav/miniconda3/lib/python3.10/site-packages (from spacy<3.6.0,>=3.5.0->en-core-web-sm==3.5.0) (8.1.7)\n",
            "Requirement already satisfied: wasabi<1.2.0,>=0.9.1 in /Users/chandramaniyadav/miniconda3/lib/python3.10/site-packages (from spacy<3.6.0,>=3.5.0->en-core-web-sm==3.5.0) (1.1.1)\n",
            "Requirement already satisfied: srsly<3.0.0,>=2.4.3 in /Users/chandramaniyadav/miniconda3/lib/python3.10/site-packages (from spacy<3.6.0,>=3.5.0->en-core-web-sm==3.5.0) (2.4.5)\n",
            "Requirement already satisfied: catalogue<2.1.0,>=2.0.6 in /Users/chandramaniyadav/miniconda3/lib/python3.10/site-packages (from spacy<3.6.0,>=3.5.0->en-core-web-sm==3.5.0) (2.0.8)\n",
            "Requirement already satisfied: typer<0.8.0,>=0.3.0 in /Users/chandramaniyadav/miniconda3/lib/python3.10/site-packages (from spacy<3.6.0,>=3.5.0->en-core-web-sm==3.5.0) (0.7.0)\n",
            "Requirement already satisfied: pathy>=0.10.0 in /Users/chandramaniyadav/miniconda3/lib/python3.10/site-packages (from spacy<3.6.0,>=3.5.0->en-core-web-sm==3.5.0) (0.10.1)\n",
            "Requirement already satisfied: smart-open<7.0.0,>=5.2.1 in /Users/chandramaniyadav/miniconda3/lib/python3.10/site-packages (from spacy<3.6.0,>=3.5.0->en-core-web-sm==3.5.0) (5.2.1)\n",
            "Requirement already satisfied: tqdm<5.0.0,>=4.38.0 in /Users/chandramaniyadav/miniconda3/lib/python3.10/site-packages (from spacy<3.6.0,>=3.5.0->en-core-web-sm==3.5.0) (4.64.1)\n",
            "Requirement already satisfied: numpy>=1.15.0 in /Users/chandramaniyadav/miniconda3/lib/python3.10/site-packages (from spacy<3.6.0,>=3.5.0->en-core-web-sm==3.5.0) (1.23.5)\n",
            "Requirement already satisfied: requests<3.0.0,>=2.13.0 in /Users/chandramaniyadav/miniconda3/lib/python3.10/site-packages (from spacy<3.6.0,>=3.5.0->en-core-web-sm==3.5.0) (2.28.2)\n",
            "Requirement already satisfied: pydantic!=1.8,!=1.8.1,<1.11.0,>=1.7.4 in /Users/chandramaniyadav/miniconda3/lib/python3.10/site-packages (from spacy<3.6.0,>=3.5.0->en-core-web-sm==3.5.0) (1.10.5)\n",
            "Requirement already satisfied: jinja2 in /Users/chandramaniyadav/miniconda3/lib/python3.10/site-packages (from spacy<3.6.0,>=3.5.0->en-core-web-sm==3.5.0) (3.1.2)\n",
            "Requirement already satisfied: setuptools in /Users/chandramaniyadav/miniconda3/lib/python3.10/site-packages (from spacy<3.6.0,>=3.5.0->en-core-web-sm==3.5.0) (67.1.0)\n",
            "Requirement already satisfied: packaging>=20.0 in /Users/chandramaniyadav/miniconda3/lib/python3.10/site-packages (from spacy<3.6.0,>=3.5.0->en-core-web-sm==3.5.0) (23.0)\n",
            "Requirement already satisfied: langcodes<4.0.0,>=3.2.0 in /Users/chandramaniyadav/miniconda3/lib/python3.10/site-packages (from spacy<3.6.0,>=3.5.0->en-core-web-sm==3.5.0) (3.3.0)\n",
            "Requirement already satisfied: typing-extensions>=4.2.0 in /Users/chandramaniyadav/miniconda3/lib/python3.10/site-packages (from pydantic!=1.8,!=1.8.1,<1.11.0,>=1.7.4->spacy<3.6.0,>=3.5.0->en-core-web-sm==3.5.0) (4.4.0)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /Users/chandramaniyadav/miniconda3/lib/python3.10/site-packages (from requests<3.0.0,>=2.13.0->spacy<3.6.0,>=3.5.0->en-core-web-sm==3.5.0) (2.1.1)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /Users/chandramaniyadav/miniconda3/lib/python3.10/site-packages (from requests<3.0.0,>=2.13.0->spacy<3.6.0,>=3.5.0->en-core-web-sm==3.5.0) (3.4)\n",
            "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /Users/chandramaniyadav/miniconda3/lib/python3.10/site-packages (from requests<3.0.0,>=2.13.0->spacy<3.6.0,>=3.5.0->en-core-web-sm==3.5.0) (1.26.14)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /Users/chandramaniyadav/miniconda3/lib/python3.10/site-packages (from requests<3.0.0,>=2.13.0->spacy<3.6.0,>=3.5.0->en-core-web-sm==3.5.0) (2023.5.7)\n",
            "Requirement already satisfied: blis<0.8.0,>=0.7.8 in /Users/chandramaniyadav/miniconda3/lib/python3.10/site-packages (from thinc<8.2.0,>=8.1.0->spacy<3.6.0,>=3.5.0->en-core-web-sm==3.5.0) (0.7.9)\n",
            "Requirement already satisfied: confection<1.0.0,>=0.0.1 in /Users/chandramaniyadav/miniconda3/lib/python3.10/site-packages (from thinc<8.2.0,>=8.1.0->spacy<3.6.0,>=3.5.0->en-core-web-sm==3.5.0) (0.0.4)\n",
            "Requirement already satisfied: click<9.0.0,>=7.1.1 in /Users/chandramaniyadav/miniconda3/lib/python3.10/site-packages (from typer<0.8.0,>=0.3.0->spacy<3.6.0,>=3.5.0->en-core-web-sm==3.5.0) (8.1.3)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /Users/chandramaniyadav/miniconda3/lib/python3.10/site-packages (from jinja2->spacy<3.6.0,>=3.5.0->en-core-web-sm==3.5.0) (2.1.2)\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n",
            "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m23.3.1\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m23.3.2\u001b[0m\n",
            "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpip install --upgrade pip\u001b[0m\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[38;5;2m✔ Download and installation successful\u001b[0m\n",
            "You can now load the package via spacy.load('en_core_web_sm')\n"
          ]
        }
      ],
      "source": [
        "\n",
        "if is_small_spacy:\n",
        "  spacy.cli.download(\"en_core_web_sm\")\n",
        "  nlp = spacy.load('en_core_web_sm')\n",
        "else:\n",
        "  spacy.cli.download(\"en_core_web_lg\")\n",
        "  nlp = spacy.load('en_core_web_lg')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 24,
      "metadata": {
        "id": "C4kATdTYATfZ"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "(3428, 2)\n"
          ]
        }
      ],
      "source": [
        "df = pd.read_csv('/Users/chandramaniyadav/Desktop/My Research Works/Cheating Detection with Generative AI/df_main.csv')\n",
        "print(df.shape)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 25,
      "metadata": {
        "id": "AaVTfaARAf2K"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "<class 'pandas.core.frame.DataFrame'>\n",
            "RangeIndex: 3428 entries, 0 to 3427\n",
            "Data columns (total 2 columns):\n",
            " #   Column  Non-Null Count  Dtype \n",
            "---  ------  --------------  ----- \n",
            " 0   text    3415 non-null   object\n",
            " 1   label   3428 non-null   int64 \n",
            "dtypes: int64(1), object(1)\n",
            "memory usage: 53.7+ KB\n"
          ]
        }
      ],
      "source": [
        "\n",
        "df.info()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 26,
      "metadata": {
        "id": "1XijcoRMAjgB"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "3428"
            ]
          },
          "execution_count": 26,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "df['text'] = df['text'].fillna('N/A')\n",
        "len(df)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 29,
      "metadata": {
        "id": "da-FC5DkAlW1"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "      text  label\n",
            "470    N/A      1\n",
            "998    N/A      1\n",
            "1014   N/A      1\n",
            "1297   N/A      1\n",
            "1430   idk      1\n",
            "1525   N/A      1\n",
            "1542   N/A      1\n",
            "1689   N/A      1\n",
            "1739   N/A      1\n",
            "1760  nbsp      1\n",
            "2153   idk      1\n",
            "2551  nbsp      1\n",
            "2786   N/A      1\n",
            "3021   N/A      1\n",
            "3205   N/A      1\n",
            "3216  nbsp      1\n",
            "3220   N/A      1\n",
            "3397   N/A      1\n"
          ]
        }
      ],
      "source": [
        "duplicated_rows = df[df.duplicated(keep=False)]\n",
        "duplicated_rows = df[df.duplicated(keep=False)]\n",
        "print(duplicated_rows)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "id": "eR9nXWfyAtkH"
      },
      "outputs": [],
      "source": [
        "df = df.drop_duplicates()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "id": "iKA52hI3BbxT"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>text</th>\n",
              "      <th>label</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>count</th>\n",
              "      <td>3413</td>\n",
              "      <td>3413.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>unique</th>\n",
              "      <td>3413</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>top</th>\n",
              "      <td>nbspnbspnbspnbspnbspnbspnbspin shakespeares hamlet the king of denmark is dead his brother has married his wife and taken the throne hamlet the kings son is in mourning but soon believes his uncle to be the murderer of his father in the play hamlet is driven more and more mad through his plots and paranoia and romance hamlet is left out of place as a chachter hamlet was left a madmad with a vendetta against his uncle who he must have vengence againstit may be difficult to comprehend hamlet b...</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>freq</th>\n",
              "      <td>1</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>mean</th>\n",
              "      <td>NaN</td>\n",
              "      <td>0.853501</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>std</th>\n",
              "      <td>NaN</td>\n",
              "      <td>0.353657</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>min</th>\n",
              "      <td>NaN</td>\n",
              "      <td>0.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>25%</th>\n",
              "      <td>NaN</td>\n",
              "      <td>1.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>50%</th>\n",
              "      <td>NaN</td>\n",
              "      <td>1.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>75%</th>\n",
              "      <td>NaN</td>\n",
              "      <td>1.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>max</th>\n",
              "      <td>NaN</td>\n",
              "      <td>1.000000</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                       text  \\\n",
              "count                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                  3413   \n",
              "unique                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                 3413   \n",
              "top     nbspnbspnbspnbspnbspnbspnbspin shakespeares hamlet the king of denmark is dead his brother has married his wife and taken the throne hamlet the kings son is in mourning but soon believes his uncle to be the murderer of his father in the play hamlet is driven more and more mad through his plots and paranoia and romance hamlet is left out of place as a chachter hamlet was left a madmad with a vendetta against his uncle who he must have vengence againstit may be difficult to comprehend hamlet b...   \n",
              "freq                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                      1   \n",
              "mean                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                    NaN   \n",
              "std                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                     NaN   \n",
              "min                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                     NaN   \n",
              "25%                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                     NaN   \n",
              "50%                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                     NaN   \n",
              "75%                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                     NaN   \n",
              "max                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                     NaN   \n",
              "\n",
              "              label  \n",
              "count   3413.000000  \n",
              "unique          NaN  \n",
              "top             NaN  \n",
              "freq            NaN  \n",
              "mean       0.853501  \n",
              "std        0.353657  \n",
              "min        0.000000  \n",
              "25%        1.000000  \n",
              "50%        1.000000  \n",
              "75%        1.000000  \n",
              "max        1.000000  "
            ]
          },
          "execution_count": 15,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "df.describe(include='all')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "id": "OTY3VvGdBnHd"
      },
      "outputs": [],
      "source": [
        "\n",
        "if is_auto_eda:\n",
        "  !pip install sweetviz\n",
        "\n",
        "  import sweetviz as sv\n",
        "\n",
        "  eda_report = sv.analyze(df) #, pairwise_analysis='off')\n",
        "  eda_report.show_html('NLP_Toxic_Comments_sweetviz.html')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {
        "id": "m5NmomKYB8Ta"
      },
      "outputs": [],
      "source": [
        "df_orig = df.copy()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {
        "id": "F887ppmJB1eZ"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "These PRON nsubj\n",
            "are AUX ROOT\n",
            "my PRON poss\n",
            "words NOUN attr\n",
            "of ADP prep\n",
            "one NUM nummod\n",
            "sentence NOUN pobj\n",
            ". PUNCT punct\n"
          ]
        }
      ],
      "source": [
        "\n",
        "# example:\n",
        "doc = nlp(\"These are my words of one sentence.\")\n",
        "for token in doc:\n",
        "  print(token.text, token.pos_, token.dep_)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {
        "id": "YaXI1f21CZoc"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "UsageError: Line magic function `%%time` not found.\n"
          ]
        }
      ],
      "source": [
        "# list of Doc objects\n",
        "%%time\n",
        "df['preprocessed_text'] = list(nlp.pipe(df['text']))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "metadata": {
        "id": "ISj5ulehCqCu"
      },
      "outputs": [],
      "source": [
        "def clean_doc(doc):\n",
        "  list_clean_tokens =  [token for token in doc if\n",
        "              not token.is_punct # punctuation\n",
        "              and not token.is_currency\n",
        "              and not token.is_digit\n",
        "              # and not token.is_oov # Is the token out-of-vocabulary (i.e. does it not have a word vector)?\n",
        "              and not token.is_space # Does the token consist of whitespace characters? Equivalent to token.text.isspace().\n",
        "              and not token.is_stop\n",
        "              and not token.like_num\n",
        "              and not token.like_url and ('@' not in token.text) and ('|' not in token.text)\n",
        "              # and not token.pos_ == \"PROPN\" (\"Wikipedia\")\n",
        "              ]\n",
        "  return list_clean_tokens\n",
        "\n",
        "# Lemmatizing + to lower case\n",
        "def lemma_text(doc):\n",
        "    tokens=[]\n",
        "    for token in doc:\n",
        "        if token.lemma_ != \"-PRON-\":\n",
        "            lemma = token.lemma_.lower().strip()\n",
        "        else:\n",
        "            lemma = token.lower_\n",
        "        tokens.append(lemma)\n",
        "    return tokens\n",
        "\n",
        "#create_string\n",
        "def create_string(doc):\n",
        "  new_string = ' '.join([str(token) for token in doc])\n",
        "  return new_string"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "metadata": {
        "id": "O2SsqzvAC40J"
      },
      "outputs": [],
      "source": [
        "def preprocess_all(df):\n",
        "    df['preprocessed_text'] = df['preprocessed_text'].apply(clean_doc)\n",
        "    df['preprocessed_text'] = df['preprocessed_text'].apply(lemma_text)\n",
        "    df['preprocessed_text'] = df['preprocessed_text'].apply(create_string)\n",
        "    return df"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "metadata": {
        "id": "eKIpyfREC79S"
      },
      "outputs": [
        {
          "ename": "KeyError",
          "evalue": "'preprocessed_text'",
          "output_type": "error",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
            "File \u001b[0;32m~/miniconda3/lib/python3.10/site-packages/pandas/core/indexes/base.py:3802\u001b[0m, in \u001b[0;36mIndex.get_loc\u001b[0;34m(self, key, method, tolerance)\u001b[0m\n\u001b[1;32m   3801\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m-> 3802\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_engine\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_loc\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcasted_key\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   3803\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m err:\n",
            "File \u001b[0;32m~/miniconda3/lib/python3.10/site-packages/pandas/_libs/index.pyx:138\u001b[0m, in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[0;34m()\u001b[0m\n",
            "File \u001b[0;32m~/miniconda3/lib/python3.10/site-packages/pandas/_libs/index.pyx:165\u001b[0m, in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[0;34m()\u001b[0m\n",
            "File \u001b[0;32mpandas/_libs/hashtable_class_helper.pxi:5745\u001b[0m, in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[0;34m()\u001b[0m\n",
            "File \u001b[0;32mpandas/_libs/hashtable_class_helper.pxi:5753\u001b[0m, in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[0;34m()\u001b[0m\n",
            "\u001b[0;31mKeyError\u001b[0m: 'preprocessed_text'",
            "\nThe above exception was the direct cause of the following exception:\n",
            "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
            "Cell \u001b[0;32mIn[22], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m df_preprocessed \u001b[38;5;241m=\u001b[39m \u001b[43mpreprocess_all\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdf\u001b[49m\u001b[43m)\u001b[49m\n",
            "Cell \u001b[0;32mIn[21], line 2\u001b[0m, in \u001b[0;36mpreprocess_all\u001b[0;34m(df)\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mpreprocess_all\u001b[39m(df):\n\u001b[0;32m----> 2\u001b[0m     df[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mpreprocessed_text\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m=\u001b[39m \u001b[43mdf\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mpreprocessed_text\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[38;5;241m.\u001b[39mapply(clean_doc)\n\u001b[1;32m      3\u001b[0m     df[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mpreprocessed_text\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m=\u001b[39m df[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mpreprocessed_text\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;241m.\u001b[39mapply(lemma_text)\n\u001b[1;32m      4\u001b[0m     df[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mpreprocessed_text\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m=\u001b[39m df[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mpreprocessed_text\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;241m.\u001b[39mapply(create_string)\n",
            "File \u001b[0;32m~/miniconda3/lib/python3.10/site-packages/pandas/core/frame.py:3807\u001b[0m, in \u001b[0;36mDataFrame.__getitem__\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m   3805\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcolumns\u001b[38;5;241m.\u001b[39mnlevels \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m1\u001b[39m:\n\u001b[1;32m   3806\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_getitem_multilevel(key)\n\u001b[0;32m-> 3807\u001b[0m indexer \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcolumns\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_loc\u001b[49m\u001b[43m(\u001b[49m\u001b[43mkey\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   3808\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m is_integer(indexer):\n\u001b[1;32m   3809\u001b[0m     indexer \u001b[38;5;241m=\u001b[39m [indexer]\n",
            "File \u001b[0;32m~/miniconda3/lib/python3.10/site-packages/pandas/core/indexes/base.py:3804\u001b[0m, in \u001b[0;36mIndex.get_loc\u001b[0;34m(self, key, method, tolerance)\u001b[0m\n\u001b[1;32m   3802\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_engine\u001b[38;5;241m.\u001b[39mget_loc(casted_key)\n\u001b[1;32m   3803\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m err:\n\u001b[0;32m-> 3804\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m(key) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01merr\u001b[39;00m\n\u001b[1;32m   3805\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m:\n\u001b[1;32m   3806\u001b[0m     \u001b[38;5;66;03m# If we have a listlike key, _check_indexing_error will raise\u001b[39;00m\n\u001b[1;32m   3807\u001b[0m     \u001b[38;5;66;03m#  InvalidIndexError. Otherwise we fall through and re-raise\u001b[39;00m\n\u001b[1;32m   3808\u001b[0m     \u001b[38;5;66;03m#  the TypeError.\u001b[39;00m\n\u001b[1;32m   3809\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_check_indexing_error(key)\n",
            "\u001b[0;31mKeyError\u001b[0m: 'preprocessed_text'"
          ]
        }
      ],
      "source": [
        "df_preprocessed = preprocess_all(df)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 33,
      "metadata": {
        "id": "G4vPSERkC9pb"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "1    2928\n",
              "0     500\n",
              "Name: label, dtype: int64"
            ]
          },
          "execution_count": 33,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "df['label'].value_counts()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "eYy0H4DdDDyj"
      },
      "outputs": [],
      "source": [
        "\n",
        "def plot_wordcloud(text, mask=None, figure_size=(15.0,10.0),\n",
        "                   title = None, title_size=40, image_color=False):\n",
        "\n",
        "    wordcloud = WordCloud(stopwords=STOP_WORDS,background_color='white',\n",
        "                    random_state = 42,\n",
        "                    width=800,\n",
        "                    height=400,\n",
        "                    mask = mask,\n",
        "                    collocations=False) # Do not repeat words in the cloud\n",
        "    wordcloud.generate(str(text))\n",
        "\n",
        "    plt.figure(figsize=figure_size)\n",
        "    if image_color:\n",
        "        image_colors = ImageColorGenerator(mask);\n",
        "        plt.imshow(wordcloud.recolor(color_func=image_colors), interpolation=\"bilinear\");\n",
        "        plt.title(title, fontdict={'size': title_size,\n",
        "                                  'verticalalignment': 'bottom'})\n",
        "    else:\n",
        "        plt.imshow(wordcloud);\n",
        "        plt.title(title, fontdict={'size': title_size, 'color': 'black',\n",
        "                                  'verticalalignment': 'bottom'})\n",
        "    plt.axis('off');\n",
        "    plt.tight_layout()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "GP7Og-JBDH8L"
      },
      "outputs": [],
      "source": [
        "plot_wordcloud(df_preprocessed[df_preprocessed['label']==0]['preprocessed_text'], title=\"Word Cloud of Generated essay\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "cBztktSpFnV8"
      },
      "outputs": [],
      "source": [
        "df.to_csv('/content/drive/MyDrive/Cheating Detection for AI generated/df_with_preprocess.csv')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_Tnt7avrDece"
      },
      "outputs": [],
      "source": [
        "\n",
        "X = df_preprocessed['preprocessed_text']\n",
        "y = df_preprocessed['label']"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "VpUc-SxCKrls"
      },
      "outputs": [],
      "source": [
        "X.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "62UD6hmXDjLr"
      },
      "outputs": [],
      "source": [
        "\n",
        "X_train, X_val, y_train, y_val = train_test_split(X, y, test_size=0.2, stratify=y, random_state=42)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "UfTBFno6J8AI"
      },
      "outputs": [],
      "source": [
        "np.unique(y_val, return_counts = True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "MZlbLsXxDnZR"
      },
      "outputs": [],
      "source": [
        "\n",
        "# Prepare data\n",
        "train_texts = X_train.to_list()  # List of training text samples\n",
        "train_labels = y_train.to_list()  # List of training labels (0 for non-toxic, 1 for toxic)\n",
        "\n",
        "val_texts = X_val.to_list()  # List of val text samples\n",
        "val_labels = y_val.to_list()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "BNR3hpBdcUHd"
      },
      "outputs": [],
      "source": [
        "from sklearn.metrics import cohen_kappa_score, roc_auc_score"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "zpDlnW9mcIbT"
      },
      "outputs": [],
      "source": [
        "def get_fp_score(CM) :\n",
        "    TN = CM[0][0]\n",
        "    FN = CM[1][0]\n",
        "    TP = CM[1][1]\n",
        "    FP = CM[0][1]\n",
        "\n",
        "    print (TN, FP)\n",
        "\n",
        "    return FP / (FP + TN)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "laTdzTO1SMXx"
      },
      "outputs": [],
      "source": [
        "results_df = pd.DataFrame(columns=['Accuracy', 'Precision', 'Recall', 'QWK', 'F1-score', 'Confusion Matrix', 'FP Score'])\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "DwMTsMOVRM0W"
      },
      "outputs": [],
      "source": [
        "def store_results(model_name, y_true, y_pred, target_names):\n",
        "    accuracy = accuracy_score(y_true, y_pred)\n",
        "    precision = precision_score(y_true, y_pred)\n",
        "    recall = recall_score(y_true, y_pred)\n",
        "    f1 = f1_score(y_true, y_pred)\n",
        "    qwk = cohen_kappa_score(y_true, y_pred, weights='quadratic')\n",
        "\n",
        "\n",
        "\n",
        "    report = classification_report(y_true, y_pred, target_names=target_names)\n",
        "    cm = confusion_matrix(y_true, y_pred)\n",
        "    false_positive = get_fp_score(cm)\n",
        "\n",
        "    results_df.loc[model_name] = [accuracy, precision, recall,qwk, f1, cm, false_positive]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "5Mn6E2NkDpOk"
      },
      "outputs": [],
      "source": [
        "\n",
        "target_names = ['Generated', 'Non-Generated']\n",
        "\n",
        "def print_results(y_true, y_pred):\n",
        "  accuracy = accuracy_score(y_true, y_pred)\n",
        "  precision = precision_score(y_true, y_pred)\n",
        "  recall = recall_score(y_true, y_pred)\n",
        "  f1 = f1_score(y_true, y_pred)\n",
        "\n",
        "  print(f'Accuracy: {accuracy:.4f}')\n",
        "  print(f'Precision: {precision:.4f}')\n",
        "  print(f'Recall: {recall:.4f}')\n",
        "  print(f'F1-score: {f1:.4f}')\n",
        "\n",
        "  # Classification Report\n",
        "  report = classification_report(y_true, y_pred, target_names=target_names)\n",
        "  print(f\"\\nClassification Report:\\n{report}\")\n",
        "\n",
        "  # Confusion Matrix\n",
        "  cm = confusion_matrix(y_true, y_pred)\n",
        "  print('Confusion Matrix:')\n",
        "  print(cm)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "RfTxfetdEX6E"
      },
      "outputs": [],
      "source": [
        "max_features=30000\n",
        "\n",
        "vectorizer = TfidfVectorizer(max_features=max_features)\n",
        "X_train_vec = vectorizer.fit_transform(X_train)\n",
        "X_val_vec = vectorizer.transform(X_val)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ha7xze2OGAwx"
      },
      "outputs": [],
      "source": [
        "df = pd.DataFrame(data=X_train_vec.todense(), columns=vectorizer.get_feature_names_out())\n",
        "print(df)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "mBKk8ds7R7BH"
      },
      "outputs": [],
      "source": [
        "X_train_vec"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "baNAWjSUGYqK"
      },
      "outputs": [],
      "source": [
        "df.to_csv('/content/drive/MyDrive/Cheating Detection for AI generated/Features.csv', index = False)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Iibh3VDbEYHa"
      },
      "outputs": [],
      "source": [
        "\n",
        "# Train the logistic regression classifier\n",
        "log_reg_classifier = LogisticRegression()\n",
        "log_reg_classifier.fit(X_train_vec, y_train)\n",
        "\n",
        "# Predict on the val set\n",
        "y_pred = log_reg_classifier.predict(X_val_vec)\n",
        "\n",
        "# Evaluate the model\n",
        "print(\"Logistic Regression:\")\n",
        "print_results(y_val, y_pred)\n",
        "store_results('Logistic Regression', y_val, y_pred, target_names)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "hk5H0f3JSn5w"
      },
      "outputs": [],
      "source": [
        "results_df"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "WOycNMX1EaYs"
      },
      "outputs": [],
      "source": [
        "# Train the LinearSVC classifier\n",
        "svc_classifier = LinearSVC() # (TODO: random_state=42, dual=False, max_iter=1000)\n",
        "svc_classifier.fit(X_train_vec, y_train)\n",
        "\n",
        "# Predict on the val set\n",
        "y_pred = svc_classifier.predict(X_val_vec)\n",
        "\n",
        "# Evaluate the model\n",
        "print(\"LinearSVC:\")\n",
        "print_results(y_val, y_pred)\n",
        "store_results('SVM', y_val, y_pred, target_names)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "eJ4_tY1cEgjq"
      },
      "outputs": [],
      "source": [
        "# Train the Multinomial Naive Bayes classifier\n",
        "nb_classifier = MultinomialNB()\n",
        "nb_classifier.fit(X_train_vec, y_train)\n",
        "\n",
        "# Predict on the val set\n",
        "y_pred = nb_classifier.predict(X_val_vec)\n",
        "\n",
        "# Evaluate the model\n",
        "print(\"Multinomial Naive Bayes:\")\n",
        "print_results(y_val, y_pred)\n",
        "store_results('Naive Bayes', y_val, y_pred, target_names)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "9EsE4zZLEkCs"
      },
      "outputs": [],
      "source": [
        "results_df"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "GRaobJEITwwr"
      },
      "outputs": [],
      "source": [
        "from sklearn.ensemble import GradientBoostingClassifier, RandomForestClassifier\n",
        "from sklearn.tree import DecisionTreeClassifier\n",
        "\n",
        "# Train the Gradient Boosting classifier\n",
        "gb_classifier = GradientBoostingClassifier()\n",
        "gb_classifier.fit(X_train_vec, y_train)\n",
        "\n",
        "# Predict on the validation set\n",
        "y_pred_gb = gb_classifier.predict(X_val_vec)\n",
        "\n",
        "# Evaluate the Gradient Boosting model\n",
        "print(\"Gradient Boosting:\")\n",
        "print_results(y_val, y_pred_gb)\n",
        "store_results('Gradient Boosting', y_val, y_pred_gb, target_names)\n",
        "\n",
        "# Train the Random Forest classifier\n",
        "rf_classifier = RandomForestClassifier()\n",
        "rf_classifier.fit(X_train_vec, y_train)\n",
        "\n",
        "# Predict on the validation set\n",
        "y_pred_rf = rf_classifier.predict(X_val_vec)\n",
        "\n",
        "# Evaluate the Random Forest model\n",
        "print(\"Random Forest:\")\n",
        "print_results(y_val, y_pred_rf)\n",
        "store_results('Random Forest', y_val, y_pred_rf, target_names)\n",
        "\n",
        "# Train the Decision Tree classifier\n",
        "dt_classifier = DecisionTreeClassifier()\n",
        "dt_classifier.fit(X_train_vec, y_train)\n",
        "\n",
        "# Predict on the validation set\n",
        "y_pred_dt = dt_classifier.predict(X_val_vec)\n",
        "\n",
        "# Evaluate the Decision Tree model\n",
        "print(\"Decision Tree:\")\n",
        "print_results(y_val, y_pred_dt)\n",
        "store_results('Decision Tree', y_val, y_pred_dt, target_names)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "QiVPI-2vUHDf"
      },
      "outputs": [],
      "source": [
        "results_df"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "lu7Au3J5ULtt"
      },
      "outputs": [],
      "source": [
        "\n",
        "PRE_TRAINED_MODEL_NAME = 'bert-base-uncased'\n",
        "MAX_LEN = 512 # (TODO: change to 128? or something else?)\n",
        "BATCH_SIZE = 16\n",
        "NUM_CLASSES = 2"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "3QNO_ZVfVW8h"
      },
      "outputs": [],
      "source": [
        "tokenizer = BertTokenizer.from_pretrained(PRE_TRAINED_MODEL_NAME, do_lower_case = True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "vRkQGLE0VXOj"
      },
      "outputs": [],
      "source": [
        "\n",
        "max_sentence_len_tokens = 0\n",
        "input_ids_lens = []\n",
        "\n",
        "# For every sentence...\n",
        "for sentence in df_preprocessed['preprocessed_text']:\n",
        "\n",
        "    # Tokenize the text and add `[CLS]` (sentence start), and `[SEP]` (sentence end) tokens.\n",
        "    input_ids = tokenizer.encode(sentence, add_special_tokens = True) # (TODO: add max_length=512, truncation=True if needed)\n",
        "\n",
        "    # append to list of lens\n",
        "    input_ids_lens.append(len(input_ids))\n",
        "\n",
        "    # Update the maximum sentence length.\n",
        "    max_sentence_len_tokens = max(max_sentence_len_tokens, len(input_ids))\n",
        "\n",
        "print('Max sentence length (tokens):', max_sentence_len_tokens)\n",
        "print('Total number of tokens in all sentences (including special tokens):', sum(input_ids_lens))\n",
        "\n",
        "# Old - Seaborn\n",
        "# sns.histplot(input_ids_lens)\n",
        "# plt.xlim([0, 400])\n",
        "# plt.xlabel('Number of tokens in a sentence')\n",
        "# plt.title(\"Num tokens Histogram\");\n",
        "\n",
        "# Use Plotly instead of Seaborn\n",
        "fig = go.Figure(data=[go.Histogram(x=input_ids_lens)])\n",
        "fig.update_layout(\n",
        "    xaxis=dict(title='Number of tokens in a sentence'),\n",
        "    yaxis=dict(title='Count'),\n",
        "    title=\"Num tokens Histogram\",\n",
        "    bargap=0.1\n",
        ")\n",
        "fig.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "GVHPyBOPVc6m"
      },
      "outputs": [],
      "source": [
        "# Tokenize and encode the texts\n",
        "train_encodings = tokenizer(train_texts, truncation=True, padding=True, max_length=MAX_LEN)\n",
        "val_encodings = tokenizer(val_texts, truncation=True, padding=True, max_length=MAX_LEN)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "TVeJIhHpVj71"
      },
      "outputs": [],
      "source": [
        "class EssayDataset(Dataset):\n",
        "    def __init__(self, encodings, labels):\n",
        "        self.encodings = encodings\n",
        "        self.labels = labels\n",
        "\n",
        "    def __getitem__(self, index):\n",
        "        item = {key: torch.tensor(val[index]) for key, val in self.encodings.items()}\n",
        "        item['labels'] = torch.tensor(self.labels[index])\n",
        "        return item\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.labels)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "rAHeVjhQVqsj"
      },
      "outputs": [],
      "source": [
        "\n",
        "train_dataset = EssayDataset(train_encodings, train_labels)\n",
        "val_dataset = EssayDataset(val_encodings, val_labels)\n",
        "train_loader = DataLoader(train_dataset, batch_size=BATCH_SIZE, shuffle=True)\n",
        "val_loader = DataLoader(val_dataset, batch_size=BATCH_SIZE, shuffle=False)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "HuGk_MtHVusC"
      },
      "outputs": [],
      "source": [
        "model = BertForSequenceClassification.from_pretrained(\n",
        "    PRE_TRAINED_MODEL_NAME,\n",
        "    num_labels = NUM_CLASSES,\n",
        "    output_attentions = False,\n",
        "    output_hidden_states = False,\n",
        ")\n",
        "\n",
        "# we don't need this really: model.classifier = nn.Linear(in_features=model.config.hidden_size, out_features=NUM_CLASSES)\n",
        "\n",
        "model = model.to(device)\n",
        "\n",
        "print(model)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "mr1X4XFDVu87"
      },
      "outputs": [],
      "source": [
        "optimizer = AdamW(model.parameters(), lr = 2e-5, eps = 1e-08) # (TODO: play with hyperparameters: lr = 5e-5, eps = 1e)\n",
        "\n",
        "loss_func = nn.CrossEntropyLoss()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "mfnndpd_V5A-"
      },
      "outputs": [],
      "source": [
        "num_epochs = 4"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "tJpbX7-ZV2L-"
      },
      "outputs": [],
      "source": [
        "\n",
        "%%time\n",
        "model.train()  # Set the model to training mode\n",
        "\n",
        "\n",
        "for epoch in trange(num_epochs): # trange - used to make our loops show a smart progress meter\n",
        "    time_str = datetime.now()\n",
        "    print(time_str)\n",
        "    total_loss = 0\n",
        "    for batch in train_loader:\n",
        "        optimizer.zero_grad()\n",
        "        input_ids = batch['input_ids'].to(device)\n",
        "        attention_mask = batch['attention_mask'].to(device)\n",
        "        labels = batch['labels'].to(device)\n",
        "\n",
        "        outputs = model(input_ids, attention_mask=attention_mask, labels=labels)\n",
        "\n",
        "        #loss = outputs.loss (this line was before using loss_func)\n",
        "        logits = outputs.logits\n",
        "        loss = loss_func(logits, labels)\n",
        "\n",
        "        total_loss += loss.item()\n",
        "\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "    avg_loss = total_loss / len(train_loader)\n",
        "    print(f'Epoch {epoch + 1}/{num_epochs} - Loss: {avg_loss:.4f}')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "rLMfX8qXV2ba"
      },
      "outputs": [],
      "source": [
        "def evaluate(data_loader):\n",
        "  # Put the model into evaluation mode which disables dropout and batch normalization layers\n",
        "  model.eval()\n",
        "  '''\n",
        "  After the training loop, you can call model.eval() to switch the model to evaluation mode.\n",
        "  In evaluation mode, the behavior of dropout and batch normalization layers changes.\n",
        "  Dropout layers no longer drop inputs, and batch normalization layers use the running statistics computed during training instead of calculating batch-wise statistics.\n",
        "  It's essential to set the model to the appropriate mode (train() or eval()),\n",
        "  as it ensures that the correct behavior is applied to the model's modules during training and evaluation/testing, respectively.\n",
        "  '''\n",
        "  y_true = []\n",
        "  y_pred = []\n",
        "\n",
        "  # The torch.no_grad() context ensures that gradients are not computed during testing, which reduces memory usage and speeds up inference\n",
        "  with torch.no_grad():\n",
        "    for batch in data_loader:\n",
        "      input_ids = batch['input_ids'].to(device)\n",
        "      attention_mask = batch['attention_mask'].to(device)\n",
        "      labels = batch['labels'].to(device)\n",
        "\n",
        "      outputs = model(input_ids, attention_mask=attention_mask)\n",
        "\n",
        "      # this line was before using softmax\n",
        "      #_, predicted = torch.max(outputs.logits, dim=1)\n",
        "\n",
        "      # Obtain the model's logits\n",
        "      logits = outputs.logits\n",
        "\n",
        "      # Add softmax activation function to obtain the probabilities for each class.\n",
        "      # Note that softmax is typically used during inference or evaluation to obtain class probabilities.\n",
        "      # During training, the model usually directly outputs logits, and the loss function handles the conversion to probabilities.\n",
        "      probabilities = F.softmax(logits, dim=1) # see https://www.pinecone.io/learn/train-sentence-transformers-softmax/\n",
        "\n",
        "      # Use torch.max to get the predicted labels based on the highest probability\n",
        "      _, predicted = torch.max(probabilities, dim=1)\n",
        "\n",
        "      # 'labels' and 'predicted' are tensors, so we cast them to numpy arrays\n",
        "      y_true.extend(labels.cpu().numpy())\n",
        "      y_pred.extend(predicted.cpu().numpy())\n",
        "\n",
        "  print(\"BERT model results:\")\n",
        "  print_results(y_true, y_pred)\n",
        "\n",
        "  return y_true, y_pred"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "vVJYLOfrYGeM"
      },
      "outputs": [],
      "source": [
        "%%time\n",
        "y_true, y_pred = evaluate(val_loader)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Zb3WTrjfYI1o"
      },
      "outputs": [],
      "source": [
        "store_results('Bert Model', y_true, y_pred, target_names)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "afnLFAhjYag8"
      },
      "outputs": [],
      "source": [
        "results_df"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "mkixPwdHYcAH"
      },
      "outputs": [],
      "source": [
        "results_df.to_csv(\"/content/drive/MyDrive/Cheating Detection for AI generated/Results of models.csv\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "r7AdSiI4y0s4"
      },
      "source": [
        "## Electra"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-u1fRCj_y68l"
      },
      "outputs": [],
      "source": [
        "results_df = pd.read_csv('/content/drive/MyDrive/Cheating Detection for AI generated/Results of models.csv')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "cVEqWqZbzRZU"
      },
      "outputs": [],
      "source": [
        "from transformers import AutoTokenizer, AutoModelForSequenceClassification"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "VIT-uzJ6ZHq-"
      },
      "outputs": [],
      "source": [
        "\n",
        "PRE_TRAINED_MODEL_NAME_ELECTRA = 'google/electra-base-discriminator'\n",
        "MAX_LEN = 512 # (TODO: change to 128? or something else?)\n",
        "BATCH_SIZE = 16\n",
        "NUM_CLASSES = 2"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-5ny06nuzQX9"
      },
      "outputs": [],
      "source": [
        "tokenizer = AutoTokenizer.from_pretrained(PRE_TRAINED_MODEL_NAME_ELECTRA, do_lower_case = True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "PXMbEa3UzzHm"
      },
      "outputs": [],
      "source": [
        "# Tokenize and encode the texts\n",
        "train_encodings = tokenizer(train_texts, truncation=True, padding=True, max_length=MAX_LEN)\n",
        "val_encodings = tokenizer(val_texts, truncation=True, padding=True, max_length=MAX_LEN)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "3VRVrpsc4IBe"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7iET2BilzzQH"
      },
      "outputs": [],
      "source": [
        "\n",
        "train_dataset = EssayDataset(train_encodings, train_labels)\n",
        "val_dataset = EssayDataset(val_encodings, val_labels)\n",
        "train_loader = DataLoader(train_dataset, batch_size=BATCH_SIZE, shuffle=True)\n",
        "val_loader = DataLoader(val_dataset, batch_size=BATCH_SIZE, shuffle=False)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "2qt0Hq8az2Us"
      },
      "outputs": [],
      "source": [
        "model = AutoModelForSequenceClassification.from_pretrained(\n",
        "    PRE_TRAINED_MODEL_NAME_ELECTRA,\n",
        "    num_labels = NUM_CLASSES,\n",
        "    output_attentions = False,\n",
        "    output_hidden_states = False,\n",
        ")\n",
        "\n",
        "# we don't need this really: model.classifier = nn.Linear(in_features=model.config.hidden_size, out_features=NUM_CLASSES)\n",
        "\n",
        "model = model.to(device)\n",
        "optimizer = AdamW(model.parameters(), lr = 2e-5, eps = 1e-08) # (TODO: play with hyperparameters: lr = 5e-5, eps = 1e)\n",
        "\n",
        "loss_func = nn.CrossEntropyLoss()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "9u_a2_aG6O9E"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "torch.cuda.empty_cache()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-wxB3KtBz_Ud"
      },
      "outputs": [],
      "source": [
        "\n",
        "%%time\n",
        "model.train()  # Set the model to training mode\n",
        "\n",
        "num_epochs = 4\n",
        "for epoch in trange(num_epochs): # trange - used to make our loops show a smart progress meter\n",
        "    time_str = datetime.now()\n",
        "    print(time_str)\n",
        "    total_loss = 0\n",
        "    for batch in train_loader:\n",
        "        optimizer.zero_grad()\n",
        "        input_ids = batch['input_ids'].to(device)\n",
        "        attention_mask = batch['attention_mask'].to(device)\n",
        "        labels = batch['labels'].to(device)\n",
        "\n",
        "        outputs = model(input_ids, attention_mask=attention_mask, labels=labels)\n",
        "\n",
        "        #loss = outputs.loss (this line was before using loss_func)\n",
        "        logits = outputs.logits\n",
        "        loss = loss_func(logits, labels)\n",
        "\n",
        "        total_loss += loss.item()\n",
        "\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "    avg_loss = total_loss / len(train_loader)\n",
        "    print(f'Epoch {epoch + 1}/{num_epochs} - Loss: {avg_loss:.4f}')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8H2aB04a0EuN"
      },
      "outputs": [],
      "source": [
        "def evaluate(data_loader):\n",
        "  # Put the model into evaluation mode which disables dropout and batch normalization layers\n",
        "  model.eval()\n",
        "  '''\n",
        "  After the training loop, you can call model.eval() to switch the model to evaluation mode.\n",
        "  In evaluation mode, the behavior of dropout and batch normalization layers changes.\n",
        "  Dropout layers no longer drop inputs, and batch normalization layers use the running statistics computed during training instead of calculating batch-wise statistics.\n",
        "  It's essential to set the model to the appropriate mode (train() or eval()),\n",
        "  as it ensures that the correct behavior is applied to the model's modules during training and evaluation/testing, respectively.\n",
        "  '''\n",
        "  y_true = []\n",
        "  y_pred = []\n",
        "\n",
        "  # The torch.no_grad() context ensures that gradients are not computed during testing, which reduces memory usage and speeds up inference\n",
        "  with torch.no_grad():\n",
        "    for batch in data_loader:\n",
        "      input_ids = batch['input_ids'].to(device)\n",
        "      attention_mask = batch['attention_mask'].to(device)\n",
        "      labels = batch['labels'].to(device)\n",
        "\n",
        "      outputs = model(input_ids, attention_mask=attention_mask)\n",
        "\n",
        "      # this line was before using softmax\n",
        "      #_, predicted = torch.max(outputs.logits, dim=1)\n",
        "\n",
        "      # Obtain the model's logits\n",
        "      logits = outputs.logits\n",
        "\n",
        "      # Add softmax activation function to obtain the probabilities for each class.\n",
        "      # Note that softmax is typically used during inference or evaluation to obtain class probabilities.\n",
        "      # During training, the model usually directly outputs logits, and the loss function handles the conversion to probabilities.\n",
        "      probabilities = F.softmax(logits, dim=1) # see https://www.pinecone.io/learn/train-sentence-transformers-softmax/\n",
        "\n",
        "      # Use torch.max to get the predicted labels based on the highest probability\n",
        "      _, predicted = torch.max(probabilities, dim=1)\n",
        "\n",
        "      # 'labels' and 'predicted' are tensors, so we cast them to numpy arrays\n",
        "      y_true.extend(labels.cpu().numpy())\n",
        "      y_pred.extend(predicted.cpu().numpy())\n",
        "\n",
        "  print(\"Electra model results:\")\n",
        "  print_results(y_true, y_pred)\n",
        "\n",
        "  return y_true, y_pred"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "IujyX8ma1SaR"
      },
      "outputs": [],
      "source": [
        "y_true, y_pred = evaluate(val_loader)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "5_ZmKAlu1z76"
      },
      "outputs": [],
      "source": [
        "results_df = results_df.rename(columns={'Unnamed: 0': 'Models'})"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "L0QKB68a2K8Q"
      },
      "outputs": [],
      "source": [
        "results_df"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "5MIA-fDl1bN0"
      },
      "outputs": [],
      "source": [
        "results_df = results_df.set_index(['Models'])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "NhJ2QLfj2f4M"
      },
      "outputs": [],
      "source": [
        "store_results('Electra Model', y_true, y_pred, target_names)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "91R3SFmf2iwZ"
      },
      "outputs": [],
      "source": [
        "results_df"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "GLbpHCJN5Z-Y"
      },
      "outputs": [],
      "source": [
        "results_df.to_csv(\"/content/drive/MyDrive/Cheating Detection for AI generated/Results of models.csv\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4PGdjViS3qEh"
      },
      "source": [
        "## ConVOBert"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "5bI_qEPl3VCu"
      },
      "outputs": [],
      "source": [
        "\n",
        "PRE_TRAINED_MODEL_NAME_CONVO = 'YituTech/conv-bert-base'\n",
        "MAX_LEN = 512 # (TODO: change to 128? or something else?)\n",
        "BATCH_SIZE = 16\n",
        "NUM_CLASSES = 2\n",
        "\n",
        "tokenizer = AutoTokenizer.from_pretrained(PRE_TRAINED_MODEL_NAME_CONVO, do_lower_case = True)\n",
        "\n",
        "# Tokenize and encode the texts\n",
        "train_encodings = tokenizer(train_texts, truncation=True, padding=True, max_length=MAX_LEN)\n",
        "val_encodings = tokenizer(val_texts, truncation=True, padding=True, max_length=MAX_LEN)\n",
        "\n",
        "train_dataset = EssayDataset(train_encodings, train_labels)\n",
        "val_dataset = EssayDataset(val_encodings, val_labels)\n",
        "train_loader = DataLoader(train_dataset, batch_size=BATCH_SIZE, shuffle=True)\n",
        "val_loader = DataLoader(val_dataset, batch_size=BATCH_SIZE, shuffle=False)\n",
        "\n",
        "model = AutoModelForSequenceClassification.from_pretrained(\n",
        "    PRE_TRAINED_MODEL_NAME_CONVO,\n",
        "    num_labels = NUM_CLASSES,\n",
        "    output_attentions = False,\n",
        "    output_hidden_states = False,\n",
        ")\n",
        "\n",
        "# we don't need this really: model.classifier = nn.Linear(in_features=model.config.hidden_size, out_features=NUM_CLASSES)\n",
        "\n",
        "model = model.to(device)\n",
        "\n",
        "\n",
        "model.train()  # Set the model to training mode\n",
        "'''\n",
        "\n",
        "for epoch in trange(num_epochs): # trange - used to make our loops show a smart progress meter\n",
        "    time_str = datetime.now()\n",
        "    print(time_str)\n",
        "    total_loss = 0\n",
        "    for batch in train_loader:\n",
        "        optimizer.zero_grad()\n",
        "        input_ids = batch['input_ids'].to(device)\n",
        "        attention_mask = batch['attention_mask'].to(device)\n",
        "        labels = batch['labels'].to(device)\n",
        "\n",
        "        outputs = model(input_ids, attention_mask=attention_mask, labels=labels)\n",
        "\n",
        "        #loss = outputs.loss (this line was before using loss_func)\n",
        "        logits = outputs.logits\n",
        "        loss = loss_func(logits, labels)\n",
        "\n",
        "        total_loss += loss.item()\n",
        "\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "    avg_loss = total_loss / len(train_loader)\n",
        "    print(f'Epoch {epoch + 1}/{num_epochs} - Loss: {avg_loss:.4f}')\n",
        "\n",
        "'''"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "FALvyOhB8V8N"
      },
      "outputs": [],
      "source": [
        "from transformers import TrainingArguments, Trainer, AdamW"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "cf9YfdkT8fa7"
      },
      "outputs": [],
      "source": [
        "def compute_metrics(eval_pred):\n",
        "    logits, labels = eval_pred.predictions, eval_pred.label_ids\n",
        "    preds = logits.argmax(axis=1)\n",
        "    kappa = cohen_kappa_score(labels, preds, weights='quadratic')\n",
        "    return {\"cohen_kappa\": kappa}"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "lANcAu2D8BIL"
      },
      "outputs": [],
      "source": [
        "training_args = TrainingArguments(\n",
        "  output_dir=\"./models/model_electra2_prompt_4\",\n",
        "  num_train_epochs=4,  # 1 (1 epoch gives slightly lower accuracy)\n",
        "  overwrite_output_dir=True,\n",
        "  evaluation_strategy=\"epoch\",\n",
        "  per_device_train_batch_size=32,\n",
        "  per_device_eval_batch_size=32,\n",
        "  save_total_limit = 2,\n",
        "  save_strategy = 'epoch',\n",
        "  load_best_model_at_end=False ) # Make sure all batches are of equal size)\n",
        "# Instantiate the Trainer class\n",
        "trainer = Trainer(\n",
        "      model=model,\n",
        "      args=training_args,\n",
        "      train_dataset=train_dataset,\n",
        "      eval_dataset=val_dataset,\n",
        "      compute_metrics=compute_metrics)\n",
        "trainer.train()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "jvXak_XoVwPV"
      },
      "outputs": [],
      "source": [
        "pred, actual, _ = trainer.predict(val_dataset)\n",
        "pred_labels = np.argmax(pred, axis=1)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "CBJZbpNcV1Qu"
      },
      "outputs": [],
      "source": [
        "store_results('ConvoBert Model', actual, pred_labels, target_names)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "rcX6_wWBV9I8"
      },
      "outputs": [],
      "source": [
        "results_df.to_csv('')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "vhh6rkOZ5OMs"
      },
      "outputs": [],
      "source": [
        "y_true, y_pred = evaluate(val_loader)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "xs7BGhDK5OZq"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "V100",
      "private_outputs": true,
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.9"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
